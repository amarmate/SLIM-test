{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.test_algorithms import *\n",
    "from functions.random_search import * \n",
    "from slim_gsgp_lib.datasets.data_loader import *\n",
    "import pickle\n",
    "\n",
    "datasets = [globals()[i] for i in globals() if 'load' in i][2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_size = 100 \n",
    "n_iter = 100\n",
    "n_iter_rs = 50\n",
    "n_iter_test = 30\n",
    "p_train = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SLIM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function slim_gsgp_lib.datasets.data_loader.load_ld50(X_y=True)>,\n",
       " <function slim_gsgp_lib.datasets.data_loader.load_ppb(X_y=True)>,\n",
       " <function slim_gsgp_lib.datasets.data_loader.load_bioav(X_y=True)>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[13:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing random search for ld50...\n",
      "Random search for ld50 completed!\n",
      "Results for SLIM+SIG2 on ld50 saved!\n",
      "Results for SLIM*SIG2 on ld50 saved!\n",
      "Results for SLIM+ABS on ld50 saved!\n",
      "Results for SLIM*ABS on ld50 saved!\n",
      "Results for SLIM+SIG1 on ld50 saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [1:04:37<2:09:15, 3877.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for SLIM*SIG1 on ld50 saved!\n",
      "Results for ld50 saved!\n",
      "---------------------------------------------------\n",
      "Performing random search for ppb...\n",
      "Random search for ppb completed!\n",
      "Results for SLIM+SIG2 on ppb saved!\n",
      "Results for SLIM*SIG2 on ppb saved!\n",
      "Results for SLIM+ABS on ppb saved!\n",
      "Results for SLIM*ABS on ppb saved!\n",
      "Results for SLIM+SIG1 on ppb saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [2:15:56<1:08:33, 4113.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for SLIM*SIG1 on ppb saved!\n",
      "Results for ppb saved!\n",
      "---------------------------------------------------\n",
      "Performing random search for bioav...\n",
      "Random search for bioav completed!\n",
      "Results for SLIM+SIG2 on bioav saved!\n",
      "Results for SLIM*SIG2 on bioav saved!\n",
      "Results for SLIM+ABS on bioav saved!\n",
      "Results for SLIM*ABS on bioav saved!\n",
      "Results for SLIM+SIG1 on bioav saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [3:16:21<00:00, 3927.06s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for SLIM*SIG1 on bioav saved!\n",
      "Results for bioav saved!\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset_loader in tqdm(datasets[13:]):\n",
    "    X, y = dataset_loader()\n",
    "    dataset_name = dataset_loader.__name__.split('load_')[1]\n",
    "\n",
    "    # Test if the best hyperparameters are valid\n",
    "    try: \n",
    "        with open(f\"best_params/best_slim_{dataset_name}_{pop_size}_{n_iter}_True_just_strmut.pkl\", 'rb') as f:\n",
    "            best_params = pickle.load(f)\n",
    "            print(f\"Best hyperparameters for {dataset_name} already exist!\")\n",
    "    except:\n",
    "        best_params = {}\n",
    "            \n",
    "    # Perform random search for both scaled and unscaled versions\n",
    "    if best_params == {}:\n",
    "        print(f\"Performing random search for {dataset_name}...\")\n",
    "        best_params = random_search_slim(X, y, dataset_name, scale=True, p_train=p_train,\n",
    "                                            iterations=n_iter_rs, pop_size=pop_size, n_iter=n_iter,\n",
    "                                            struct_mutation=True, show_progress=False, x_o=False, identifier='just_strmut')\n",
    "        \n",
    "        print(f\"Random search for {dataset_name} completed!\")\n",
    "    \n",
    "    # Initialize dictionaries for scaled and unscaled results\n",
    "    metrics = ['rmse_', 'mape_', 'nrmse_', 'r2_', 'mae_', 'std_rmse_', 'time_stats', 'train_fit', 'test_fit', 'size']\n",
    "    results = {metric: {} for metric in metrics}\n",
    "\n",
    "    for algorithm in best_params:\n",
    "        # Retrieve the best hyperparameters for testing\n",
    "        args = best_params[algorithm]\n",
    "\n",
    "        # Test SLIM \n",
    "        rm, ma, nrmse, r2, mae, std_rmse, time, train, test, size = test_slim(\n",
    "            X=X, y=y, args_dict=args, dataset_name=dataset_loader.__name__,\n",
    "            ms_lower=0, ms_upper=1, n_elites=1,\n",
    "            iterations=n_iter_test, scale=True, algorithm=algorithm,\n",
    "            verbose=0, p_train=p_train, show_progress=False,\n",
    "        )\n",
    "        \n",
    "        # Initialize storage for each algorithm if not already present\n",
    "        for metric in metrics:\n",
    "            if algorithm not in results[metric]:\n",
    "                results[metric][algorithm] = []\n",
    "\n",
    "        # Store results\n",
    "        results['rmse_'][algorithm].append(rm)\n",
    "        results['mape_'][algorithm].append(ma)\n",
    "        results['nrmse_'][algorithm].append(nrmse)\n",
    "        results['r2_'][algorithm].append(r2)\n",
    "        results['mae_'][algorithm].append(mae)\n",
    "        results['std_rmse_'][algorithm].append(std_rmse)\n",
    "        results['time_stats'][algorithm].append(time)\n",
    "        results['train_fit'][algorithm].append(train)\n",
    "        results['test_fit'][algorithm].append(test)\n",
    "        results['size'][algorithm].append(size)        \n",
    "\n",
    "        print(f\"Results for {algorithm} on {dataset_name} saved!\")\n",
    "\n",
    "    # Save the results to disk\n",
    "    with open(f\"results/SLIM/{dataset_name}_just_strmut.pkl\", 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "\n",
    "    print(f\"Results for {dataset_name} saved!\")\n",
    "    print(\"---------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
